# -*- coding: utf-8 -*-
"""2020-inu-2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17RSBPwccRF4x_vHcyKz6Vfx78f6qJqxb
"""

! grep -c "processor" /proc/cpuinfo

! grep "Total" /proc/meminfo

! df -H

! pwd

! ls

import sys
print(sys.version)

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x

import tensorflow as tf

print(tf.__version__)

from tensorflow.python.client import device_lib
for x in device_lib.list_local_devices():
    print(x.device_type, x.name, x.memory_limit, x.physical_device_desc)

import numpy as np 
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import os
from os.path import join

from google.colab import drive
drive.mount('/gdrive')

train_data_path = join('data', '/gdrive/My Drive/Colab Notebooks/house-data/train.csv')
test_data_path = join('data', '/gdrive/My Drive/Colab Notebooks/house-data/test.csv')

train_df = pd.read_csv(train_data_path)
test_df = pd.read_csv(test_data_path)

train_df.head()

test_df.head()

train_df.set_index('Id', inplace=True)
test_df.set_index('Id', inplace=True)
len_train_df = len(train_df)
len_test_df = len(test_df)

corrmat = train_df.corr()
top_corr_features = corrmat.index[abs(corrmat["SalePrice"])>=0.3]
top_corr_features

# heatmap
plt.figure(figsize=(13,10))
g = sns.heatmap(train_df[top_corr_features].corr(),annot=True,cmap="RdYlGn")

# split y_label
train_y_label = train_df['SalePrice'] 	# target 값을 미리 분리하였음.
train_df.drop(['SalePrice'], axis=1, inplace=True)

print(train_y_label.shape)

# concat train & test
boston_df = pd.concat((train_df, test_df), axis=0)
boston_df_index = boston_df.index

print('Length of Boston Dataset : ',len(boston_df))
boston_df.head()

# check null 
check_null = boston_df.isna().sum() / len(boston_df)

# columns of null ratio >= 0.5
check_null[check_null >= 0.5]

# remove columns of null ratio >= 0.5
remove_cols = check_null[check_null >= 0.5].keys()
boston_df = boston_df.drop(remove_cols, axis=1)

boston_df.head()

# split object & numeric
boston_obj_df = boston_df.select_dtypes(include='object')	# 카테고리형
boston_num_df = boston_df.select_dtypes(exclude='object')	# 수치형

print('Object type columns:\n',boston_obj_df.columns)
print('---------------------------------------------------------------------------------')
print('Numeric type columns:\n',boston_num_df.columns)

boston_dummy_df = pd.get_dummies(boston_obj_df, drop_first=True)
boston_dummy_df.index = boston_df_index
boston_dummy_df.head()

from sklearn.impute import SimpleImputer as Imputer

imputer = Imputer(strategy='mean')
imputer.fit(boston_num_df)
boston_num_df_ = imputer.transform(boston_num_df)

boston_num_df = pd.DataFrame(boston_num_df_, columns=boston_num_df.columns, index=boston_df_index)
boston_num_df.head()

boston_df = pd.merge(boston_dummy_df, boston_num_df, left_index=True, right_index=True)
boston_df.head()

train_df = boston_df[:len_train_df]
test_df = boston_df[len_train_df:]

train_df['SalePrice'] = train_y_label

print('train set length: ',len(train_df))
print('test set length: ',len(test_df))



from sklearn.model_selection import train_test_split

X_train = train_df.drop(['SalePrice'], axis=1)
y_train = train_df['SalePrice']

X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=True)

X_test = test_df
test_id_idx = test_df.index

print('X_train : ',len(X_train))
print('X_val : ',len(X_val))
print('X_test :',len(X_test))

print(X_train.shape)

from tensorflow.keras import models
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Dropout

nb_input = X_train.shape[1]
nb_nodes = 150

model = models.Sequential()

model.add(Dense(5*nb_nodes, input_dim=nb_input, activation='relu'))
model.add(Dropout(0.5))

# model.add(Dense(5*nb_nodes, activation='relu'))
# model.add(Dropout(0.2))

# model.add(Dense(4*nb_nodes, activation='relu'))
# model.add(Dropout(0.3))

# model.add(Dense(2*nb_nodes, activation='relu'))
# model.add(Dropout(0.4))

# model.add(Dense(1*nb_nodes, activation='relu'))
# model.add(Dropout(0.5))

model.add(Dense(10, activation='relu'))

model.add(Dense(2*nb_nodes, activation='relu'))
model.add(Dropout(0.4))

model.add(Dense(1, activation='linear'))

model.summary()

opt = ['adam', 'rmsprop', 'sgd']
loss = ['mse', 'mean_squared_error']
met = ['mae', 'accuracy']
model.compile(optimizer=opt[0], loss=loss[0])

from keras.callbacks import EarlyStopping

monitor = EarlyStopping(patience = 50)
hist = model.fit(X_train , y_train, epochs=1000, batch_size=32, validation_split=0.2, callbacks=[monitor])
model.save('house-inu.h5')

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt

fig, loss_ax = plt.subplots()
# acc_ax = loss_ax.twinx()

loss_ax.plot(hist.history['loss'], 'y', label='train loss')
loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')
# acc_ax.plot(hist.history['acc'], 'b', label='train acc')
# acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')

loss_ax.set_xlabel('epoch')
loss_ax.set_ylabel('loss')
# acc_ax.set_ylabel('mean_squared_error')

loss_ax.legend(loc='upper left')
# acc_ax.legend(loc='upper right')

plt.show()

filename = 'house_inu'
model.save(filename+'.h5')

print(X_test)

output = model.predict(X_test)

print(output.shape)

test_df.columns

print(test_id_idx)

pred = pd.DataFrame( data = {'Id': test_id_idx, 'SalePrice':output.flatten()})
pred.describe()

pred.head()

pred.to_csv('/gdrive/My Drive/Colab Notebooks/'+'house-inu-res'+'.csv', index=False)

